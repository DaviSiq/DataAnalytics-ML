{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1daea395",
   "metadata": {},
   "source": [
    "### Predictive modeling of Orders (Order_payment, review, items and Orders)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5b6afc",
   "metadata": {},
   "source": [
    "#### Juntando todas as tabelas em uma s√≥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e91bf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando tabelas do Snowflake...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_28908\\3132649183.py:29: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_orders = pd.read_sql(\"SELECT * FROM orders_refined\", conn)\n",
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_28908\\3132649183.py:30: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_orders_reviews = pd.read_sql(\"SELECT * FROM order_reviews_refined\", conn)\n",
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_28908\\3132649183.py:31: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_order_payments = pd.read_sql(\"SELECT * FROM order_payments_refined\", conn)\n",
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_28908\\3132649183.py:32: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_order_items = pd.read_sql(\"SELECT * FROM order_items_refined\", conn)\n",
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_28908\\3132649183.py:33: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_products = pd.read_sql(\"SELECT * FROM products_refined\", conn)\n",
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_28908\\3132649183.py:35: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_customers = pd.read_sql(\"SELECT * FROM customers_refined\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unindo as tabelas...\n",
      "Jun√ß√£o completa. O DataFrame final tem o formato: (476572, 56)\n",
      "                           order_id                       customer_id  \\\n",
      "0  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
      "1  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
      "2  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
      "3  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
      "4  85ce859fd6dc634de8d2f1e290444043  059f7fc5719c7da6cbafe370971a8d70   \n",
      "\n",
      "  order_status order_purchase_timestamp    order_approved_at  \\\n",
      "0    delivered      1511033286000000000  1511034359000000000   \n",
      "1    delivered      1511033286000000000  1511034359000000000   \n",
      "2    delivered      1511033286000000000  1511034359000000000   \n",
      "3    delivered      1511033286000000000  1511034359000000000   \n",
      "4    delivered      1511222621000000000  1511223262000000000   \n",
      "\n",
      "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
      "0          1511357999000000000           1512174522000000000   \n",
      "1          1511357999000000000           1512174522000000000   \n",
      "2          1511357999000000000           1512174522000000000   \n",
      "3          1511357999000000000           1512174522000000000   \n",
      "4          1511472746000000000           1511807280000000000   \n",
      "\n",
      "  order_estimated_delivery_date approval_time_hours processing_time_hours  \\\n",
      "0           1513296000000000000                 0.3                  89.9   \n",
      "1           1513296000000000000                 0.3                  89.9   \n",
      "2           1513296000000000000                 0.3                  89.9   \n",
      "3           1513296000000000000                 0.3                  89.9   \n",
      "4           1512950400000000000                0.18                  69.3   \n",
      "\n",
      "   ... product_photos_qty product_weight_g product_length_cm  \\\n",
      "0  ...                  3              450                30   \n",
      "1  ...                  3              450                30   \n",
      "2  ...                  3              450                30   \n",
      "3  ...                  3              450                30   \n",
      "4  ...                  1              250                40   \n",
      "\n",
      "  product_height_cm product_width_cm product_volume_cm3 product_density_g_cm3  \\\n",
      "0                10               20               6000                 0.075   \n",
      "1                10               20               6000                 0.075   \n",
      "2                10               20               6000                 0.075   \n",
      "3                10               20               6000                 0.075   \n",
      "4                 4               30               4800                0.0521   \n",
      "\n",
      "  description_category customer_state customer_zip_code_prefix  \n",
      "0      Descri√ß√£o longa             RN                    59296  \n",
      "1      Descri√ß√£o longa             RN                    59296  \n",
      "2      Descri√ß√£o longa             RN                    59296  \n",
      "3      Descri√ß√£o longa             RN                    59296  \n",
      "4      Descri√ß√£o m√©dia             SP                    13186  \n",
      "\n",
      "[5 rows x 56 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import snowflake.connector\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "# Carrega as vari√°veis de ambiente\n",
    "env_path = Path('.') / 'environment.env'\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "SF_USER = os.getenv(\"SF_USER\")\n",
    "SF_PASSWORD = os.getenv(\"SF_PASSWORD\")\n",
    "SF_ACCOUNT = os.getenv(\"SF_ACCOUNT\")\n",
    "SF_WAREHOUSE = os.getenv(\"SF_WAREHOUSE\")\n",
    "SF_DATABASE = os.getenv(\"SF_DATABASE\")\n",
    "SF_SCHEMA = os.getenv(\"SF_SCHEMA\")\n",
    "\n",
    "# Conecta ao Snowflake\n",
    "conn = snowflake.connector.connect(\n",
    "    user=SF_USER,\n",
    "    password=SF_PASSWORD,\n",
    "    account=SF_ACCOUNT,\n",
    "    warehouse=SF_WAREHOUSE,\n",
    "    database=SF_DATABASE,\n",
    "    schema=SF_SCHEMA\n",
    ")\n",
    "\n",
    "# Carrega as tabelas\n",
    "print(\"Carregando tabelas do Snowflake...\")\n",
    "df_orders = pd.read_sql(\"SELECT * FROM orders_refined\", conn)\n",
    "df_orders_reviews = pd.read_sql(\"SELECT * FROM order_reviews_refined\", conn)\n",
    "df_order_payments = pd.read_sql(\"SELECT * FROM order_payments_refined\", conn)\n",
    "df_order_items = pd.read_sql(\"SELECT * FROM order_items_refined\", conn)\n",
    "df_products = pd.read_sql(\"SELECT * FROM products_refined\", conn)\n",
    "# üí° NOVO: Carregando a tabela de clientes\n",
    "df_customers = pd.read_sql(\"SELECT * FROM customers_refined\", conn)\n",
    "\n",
    "# Fecha a conex√£o\n",
    "conn.close()\n",
    "\n",
    "# Padroniza os nomes das colunas\n",
    "for df in [df_orders, df_orders_reviews, df_order_payments, df_order_items, df_products, df_customers]:\n",
    "    df.columns = df.columns.str.lower()\n",
    "\n",
    "# Realiza as jun√ß√µes sequenciais\n",
    "print(\"Unindo as tabelas...\")\n",
    "df_full_orders = df_orders.merge(df_orders_reviews, on='order_id', how='left')\n",
    "df_full_orders = df_full_orders.merge(df_order_payments, on='order_id', how='left')\n",
    "df_full_orders = df_full_orders.merge(df_order_items, on='order_id', how='left')\n",
    "df_full_orders = df_full_orders.merge(df_products, on='product_id', how='left')\n",
    "# üí° NOVO: Juntando a tabela de clientes\n",
    "df_full_orders = df_full_orders.merge(\n",
    "    df_customers[['customer_id', 'customer_state', 'customer_zip_code_prefix']],\n",
    "    on='customer_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(\"Jun√ß√£o completa. O DataFrame final tem o formato:\", df_full_orders.shape)\n",
    "print(df_full_orders.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cd45b1",
   "metadata": {},
   "source": [
    "### Salvando de volta para csv (com todas as tabelas) para usar exemplos reais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c858c06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando tabelas do Snowflake...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_26324\\1455172169.py:29: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_orders = pd.read_sql(\"SELECT * FROM orders_refined\", conn)\n",
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_26324\\1455172169.py:30: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_orders_reviews = pd.read_sql(\"SELECT * FROM order_reviews_refined\", conn)\n",
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_26324\\1455172169.py:31: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_order_payments = pd.read_sql(\"SELECT * FROM order_payments_refined\", conn)\n",
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_26324\\1455172169.py:32: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_order_items = pd.read_sql(\"SELECT * FROM order_items_refined\", conn)\n",
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_26324\\1455172169.py:33: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_products = pd.read_sql(\"SELECT * FROM products_refined\", conn)\n",
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_26324\\1455172169.py:34: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_customers = pd.read_sql(\"SELECT * FROM customers_refined\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unindo as tabelas...\n",
      "Salvando o DataFrame completo em olist_full_dataset.csv...\n",
      "Processo conclu√≠do. O arquivo 'olist_full_dataset.csv' foi criado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import snowflake.connector\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "# Carrega as vari√°veis de ambiente\n",
    "env_path = Path('.') / 'environment.env'\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "SF_USER = os.getenv(\"SF_USER\")\n",
    "SF_PASSWORD = os.getenv(\"SF_PASSWORD\")\n",
    "SF_ACCOUNT = os.getenv(\"SF_ACCOUNT\")\n",
    "SF_WAREHOUSE = os.getenv(\"SF_WAREHOUSE\")\n",
    "SF_DATABASE = os.getenv(\"SF_DATABASE\")\n",
    "SF_SCHEMA = os.getenv(\"SF_SCHEMA\")\n",
    "\n",
    "# Conecta ao Snowflake\n",
    "conn = snowflake.connector.connect(\n",
    "    user=SF_USER,\n",
    "    password=SF_PASSWORD,\n",
    "    account=SF_ACCOUNT,\n",
    "    warehouse=SF_WAREHOUSE,\n",
    "    database=SF_DATABASE,\n",
    "    schema=SF_SCHEMA\n",
    ")\n",
    "\n",
    "# Carrega as tabelas\n",
    "print(\"Carregando tabelas do Snowflake...\")\n",
    "df_orders = pd.read_sql(\"SELECT * FROM orders_refined\", conn)\n",
    "df_orders_reviews = pd.read_sql(\"SELECT * FROM order_reviews_refined\", conn)\n",
    "df_order_payments = pd.read_sql(\"SELECT * FROM order_payments_refined\", conn)\n",
    "df_order_items = pd.read_sql(\"SELECT * FROM order_items_refined\", conn)\n",
    "df_products = pd.read_sql(\"SELECT * FROM products_refined\", conn)\n",
    "df_customers = pd.read_sql(\"SELECT * FROM customers_refined\", conn)\n",
    "\n",
    "# Fecha a conex√£o\n",
    "conn.close()\n",
    "\n",
    "# Padroniza os nomes das colunas\n",
    "for df in [df_orders, df_orders_reviews, df_order_payments, df_order_items, df_products, df_customers]:\n",
    "    df.columns = df.columns.str.lower()\n",
    "\n",
    "# Realiza as jun√ß√µes sequenciais\n",
    "print(\"Unindo as tabelas...\")\n",
    "df_full_orders = df_orders.merge(df_orders_reviews, on='order_id', how='left')\n",
    "df_full_orders = df_full_orders.merge(df_order_payments, on='order_id', how='left')\n",
    "df_full_orders = df_full_orders.merge(df_order_items, on='order_id', how='left')\n",
    "df_full_orders = df_full_orders.merge(df_products, on='product_id', how='left')\n",
    "df_full_orders = df_full_orders.merge(\n",
    "    df_customers[['customer_id', 'customer_state', 'customer_zip_code_prefix']],\n",
    "    on='customer_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Salva o DataFrame completo em um arquivo CSV\n",
    "print(\"Salvando o DataFrame completo em olist_full_dataset.csv...\")\n",
    "df_full_orders.to_csv('olist_full_dataset.csv', index=False)\n",
    "\n",
    "print(\"Processo conclu√≠do. O arquivo 'olist_full_dataset.csv' foi criado com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea2c9da",
   "metadata": {},
   "source": [
    "### Criando dataset monthly_revenue para predi√ß√£o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03a41c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparando dados para a s√©rie temporal de faturamento...\n",
      "Criando a s√©rie temporal de faturamento mensal...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_28908\\1667327117.py:40: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  pd.Grouper(key='order_purchase_datetime', freq='M')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criando features de lag e temporais...\n",
      "\n",
      "DataFrame de Faturamento Mensal com Features de Lag:\n",
      "        data                                 faturamento_mensal  \\\n",
      "3 2016-12-31                                              19.62   \n",
      "4 2017-01-31  19.6219.6211.6216.6218.6219.6220.6219.6219.621...   \n",
      "5 2017-02-28  174.5452.7847.6870.28176.3970.2840.52179.3559....   \n",
      "6 2017-03-31  52.1849.96118.0343.05188.1849.52147.0666.9940....   \n",
      "7 2017-04-30  84.1536.86204.08161.05103.1143.05114.79113.768...   \n",
      "\n",
      "                            faturamento_mes_anterior  \\\n",
      "3                                                  0   \n",
      "4                                              19.62   \n",
      "5  19.6219.6211.6216.6218.6219.6220.6219.6219.621...   \n",
      "6  174.5452.7847.6870.28176.3970.2840.52179.3559....   \n",
      "7  52.1849.96118.0343.05188.1849.52147.0666.9940....   \n",
      "\n",
      "                           faturamento_2_meses_atras  \\\n",
      "3  109.3445.4639.0935.6153.73133.4640.95154.5792....   \n",
      "4                                                  0   \n",
      "5                                              19.62   \n",
      "6  19.6219.6211.6216.6218.6219.6220.6219.6219.621...   \n",
      "7  174.5452.7847.6870.28176.3970.2840.52179.3559....   \n",
      "\n",
      "                           faturamento_3_meses_atras  mes   ano  \n",
      "3                                   136.2375.0640.95   12  2016  \n",
      "4  109.3445.4639.0935.6153.73133.4640.95154.5792....    1  2017  \n",
      "5                                                  0    2  2017  \n",
      "6                                              19.62    3  2017  \n",
      "7  19.6219.6211.6216.6218.6219.6220.6219.6219.621...    4  2017  \n",
      "\n",
      "DataFrame final tem o formato: (23, 7)\n",
      "Salvando o DataFrame de faturamento mensal em 'olist_monthly_revenue.csv'...\n",
      "Arquivo 'olist_full_dataset.csv' criado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Supondo que df_orders e df_order_payments j√° est√£o carregados\n",
    "\n",
    "# üí° FUN√á√ÉO DE CONVERS√ÉO CORRIGIDA\n",
    "# Esta fun√ß√£o garante que timestamps muito grandes sejam convertidos corretamente\n",
    "def safe_timestamp_to_datetime(series):\n",
    "    series = pd.to_numeric(series, errors='coerce')\n",
    "    if series.dropna().empty:\n",
    "        return pd.NaT\n",
    "    max_val = series.max()\n",
    "    if max_val > 1e18:           # nanosegundos\n",
    "        unit = 'ns'\n",
    "    elif max_val > 1e12:         # milissegundos\n",
    "        unit = 'ms'\n",
    "    else:                        # segundos\n",
    "        unit = 's'\n",
    "    return pd.to_datetime(series, unit=unit, errors='coerce')\n",
    "\n",
    "\n",
    "# --- 1. Jun√ß√£o e Prepara√ß√£o dos Dados ---\n",
    "print(\"Preparando dados para a s√©rie temporal de faturamento...\")\n",
    "\n",
    "# Junta pedidos e pagamentos\n",
    "df_revenue = df_orders.merge(\n",
    "    df_order_payments[['order_id', 'payment_value']],\n",
    "    on='order_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# üí° CORRE√á√ÉO: Usa a fun√ß√£o segura para converter o timestamp\n",
    "df_revenue['order_purchase_datetime'] = safe_timestamp_to_datetime(df_revenue['order_purchase_timestamp'])\n",
    "\n",
    "\n",
    "# --- 2. Cria√ß√£o da S√©rie Temporal de Faturamento Mensal ---\n",
    "print(\"Criando a s√©rie temporal de faturamento mensal...\")\n",
    "\n",
    "# Agrupa por m√™s e soma o valor dos pagamentos\n",
    "monthly_revenue = df_revenue.groupby(\n",
    "    pd.Grouper(key='order_purchase_datetime', freq='M')\n",
    ")['payment_value'].sum().reset_index()\n",
    "\n",
    "# Renomeia as colunas\n",
    "monthly_revenue.rename(columns={'order_purchase_datetime': 'data', 'payment_value': 'faturamento_mensal'}, inplace=True)\n",
    "\n",
    "\n",
    "# --- 3. Cria√ß√£o das Features de Lag e Temporais ---\n",
    "print(\"Criando features de lag e temporais...\")\n",
    "\n",
    "# Features de Lag (faturamento dos meses anteriores)\n",
    "monthly_revenue['faturamento_mes_anterior'] = monthly_revenue['faturamento_mensal'].shift(1)\n",
    "monthly_revenue['faturamento_2_meses_atras'] = monthly_revenue['faturamento_mensal'].shift(2)\n",
    "monthly_revenue['faturamento_3_meses_atras'] = monthly_revenue['faturamento_mensal'].shift(3)\n",
    "\n",
    "# Features Temporais\n",
    "monthly_revenue['mes'] = monthly_revenue['data'].dt.month\n",
    "monthly_revenue['ano'] = monthly_revenue['data'].dt.year\n",
    "\n",
    "# Remove as linhas com valores nulos (os primeiros meses que n√£o t√™m lag)\n",
    "monthly_revenue.dropna(inplace=True)\n",
    "\n",
    "# Exibe o DataFrame final\n",
    "print(\"\\nDataFrame de Faturamento Mensal com Features de Lag:\")\n",
    "print(monthly_revenue.head())\n",
    "print(f\"\\nDataFrame final tem o formato: {monthly_revenue.shape}\")\n",
    "# --- Adicione este trecho de c√≥digo ao final da sua c√©lula ---\n",
    "\n",
    "# Salva o DataFrame final em um arquivo CSV\n",
    "print(\"Salvando o DataFrame de faturamento mensal em 'olist_monthly_revenue.csv'...\")\n",
    "monthly_revenue.to_csv('olist_monthly_revenue.csv', index=False)\n",
    "\n",
    "print(\"Arquivo 'olist_full_dataset.csv' criado com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ab4eeb",
   "metadata": {},
   "source": [
    "### Treinando o modelo para prever o faturamento de um m√™s X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db284e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recriando e limpando o DataFrame de faturamento mensal...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_28908\\2723260769.py:38: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  pd.Grouper(key='order_purchase_datetime', freq='M')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Previs√£o de Faturamento do √öltimo M√™s ---\n",
      "Dados de treino: 22 meses\n",
      "Dados de teste: 1 m√™s\n",
      "\n",
      "--- An√°lise da Predi√ß√£o ---\n",
      "Faturamento real do √∫ltimo m√™s: R$ 589.67\n",
      "Faturamento previsto para o √∫ltimo m√™s: R$ 549333.32\n",
      "Diferen√ßa (Real - Previsto): R$ -548743.65\n",
      "Erro percentual: 93059.45%\n",
      "\n",
      "--- Salvando o DataFrame de Faturamento Mensal ---\n",
      "Arquivo 'olist_monthly_revenue.csv' criado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Supondo que df_orders e df_order_payments j√° est√£o carregados na sua sess√£o\n",
    "\n",
    "# üí° FUN√á√ÉO DE CONVERS√ÉO: Necess√°ria para lidar com os timestamps\n",
    "def safe_timestamp_to_datetime(series):\n",
    "    series = pd.to_numeric(series, errors='coerce')\n",
    "    if series.dropna().empty:\n",
    "        return pd.NaT\n",
    "    max_val = series.max()\n",
    "    if max_val > 1e18:           # nanosegundos\n",
    "        unit = 'ns'\n",
    "    elif max_val > 1e12:         # milissegundos\n",
    "        unit = 'ms'\n",
    "    else:                        # segundos\n",
    "        unit = 's'\n",
    "    return pd.to_datetime(series, unit=unit, errors='coerce')\n",
    "\n",
    "\n",
    "# --- 1. Cria√ß√£o e Limpeza da S√©rie Temporal de Faturamento ---\n",
    "print(\"Recriando e limpando o DataFrame de faturamento mensal...\")\n",
    "\n",
    "df_revenue = df_orders.merge(\n",
    "    df_order_payments[['order_id', 'payment_value']],\n",
    "    on='order_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "df_revenue['payment_value'] = pd.to_numeric(df_revenue['payment_value'], errors='coerce')\n",
    "df_revenue['order_purchase_datetime'] = safe_timestamp_to_datetime(df_revenue['order_purchase_timestamp'])\n",
    "\n",
    "monthly_revenue = df_revenue.groupby(\n",
    "    pd.Grouper(key='order_purchase_datetime', freq='M')\n",
    ")['payment_value'].sum().reset_index()\n",
    "\n",
    "monthly_revenue.rename(columns={'order_purchase_datetime': 'data', 'payment_value': 'faturamento_mensal'}, inplace=True)\n",
    "\n",
    "# Cria√ß√£o das Features de Lag e Temporais\n",
    "monthly_revenue['faturamento_mes_anterior'] = monthly_revenue['faturamento_mensal'].shift(1)\n",
    "monthly_revenue['faturamento_2_meses_atras'] = monthly_revenue['faturamento_mensal'].shift(2)\n",
    "monthly_revenue['faturamento_3_meses_atras'] = monthly_revenue['faturamento_mensal'].shift(3)\n",
    "\n",
    "monthly_revenue['mes'] = monthly_revenue['data'].dt.month\n",
    "monthly_revenue['ano'] = monthly_revenue['data'].dt.year\n",
    "\n",
    "monthly_revenue.dropna(inplace=True)\n",
    "\n",
    "\n",
    "# --- 2. Treinamento e Predi√ß√£o com Random Forest Regressor ---\n",
    "print(\"\\n--- Previs√£o de Faturamento do √öltimo M√™s ---\")\n",
    "\n",
    "# üí° CORRE√á√ÉO: Usando o Random Forest Regressor como modelo principal\n",
    "features = [\n",
    "    'faturamento_mes_anterior',\n",
    "    'faturamento_2_meses_atras',\n",
    "    'faturamento_3_meses_atras',\n",
    "    'mes',\n",
    "    'ano'\n",
    "]\n",
    "\n",
    "X = monthly_revenue[features]\n",
    "y = monthly_revenue['faturamento_mensal']\n",
    "\n",
    "X_train = X.iloc[:-1]\n",
    "y_train = y.iloc[:-1]\n",
    "X_test = X.iloc[-1:]\n",
    "y_test = y.iloc[-1:]\n",
    "\n",
    "print(f\"Dados de treino: {len(X_train)} meses\")\n",
    "print(f\"Dados de teste: {len(X_test)} m√™s\")\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# --- 3. An√°lise e Compara√ß√£o ---\n",
    "print(\"\\n--- An√°lise da Predi√ß√£o ---\")\n",
    "print(f\"Faturamento real do √∫ltimo m√™s: R$ {y_test.values[0]:.2f}\")\n",
    "print(f\"Faturamento previsto para o √∫ltimo m√™s: R$ {y_pred[0]:.2f}\")\n",
    "\n",
    "diferenca = y_test.values[0] - y_pred[0]\n",
    "print(f\"Diferen√ßa (Real - Previsto): R$ {diferenca:.2f}\")\n",
    "\n",
    "erro_percentual = (abs(diferenca) / y_test.values[0]) * 100\n",
    "print(f\"Erro percentual: {erro_percentual:.2f}%\")\n",
    "\n",
    "\n",
    "# --- 4. Salvando o CSV ---\n",
    "print(\"\\n--- Salvando o DataFrame de Faturamento Mensal ---\")\n",
    "monthly_revenue.to_csv('olist_monthly_revenue.csv', index=False)\n",
    "print(\"Arquivo 'olist_monthly_revenue.csv' criado com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b578d4ca",
   "metadata": {},
   "source": [
    "- Os dados s√£o insuficientes para gerar um treinamento que possa predizer com um grau elevado de confian√ßa o faturamento do m√™s alvo.\n",
    "- Confira o gr√°fico gerado no arquivo EDA onde mostra o aumento e diminui√ß√£o das vendas ao decorrer dos meses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec27a5c9",
   "metadata": {},
   "source": [
    "### Churn Rate (evas√£o de um cliente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e99535b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparando dados para an√°lise RFM e predi√ß√£o de Churn...\n",
      "Dados RFM e Churn criados:\n",
      "                        customer_id  recency_days  frequency_orders  \\\n",
      "0  00012a2ce6f8dcda20d059ce98491703           338                 1   \n",
      "1  000161a058600d5901f007fab4c27140           459                 1   \n",
      "2  0001fd6190edaaf884bcaf3d49edf079           597                 1   \n",
      "3  0002414f95344307404f0ace7a26f1d5           428                 1   \n",
      "4  000379cdec625522490c315e70c7a9fb           199                 1   \n",
      "\n",
      "   monetary_value  review_score  is_churn  \n",
      "0          114.74           1.0         1  \n",
      "1           67.41           4.0         1  \n",
      "2          195.42           5.0         1  \n",
      "3          179.35           5.0         1  \n",
      "4          107.01           4.0         1  \n",
      "\n",
      "--- Modelagem para prever a evas√£o de clientes (Churn) ---\n",
      "\n",
      "Treinando Logistic Regression...\n",
      "M√©tricas para Logistic Regression:\n",
      "Acur√°cia: 0.9042\n",
      "Precis√£o: 0.9042\n",
      "Recall: 1.0000\n",
      "F1-Score: 0.9497\n",
      "\n",
      "Treinando Random Forest Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_28908\\3029396872.py:92: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  rfm_df['review_score'].fillna(rfm_df['review_score'].mean(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M√©tricas para Random Forest Classifier:\n",
      "Acur√°cia: 0.8740\n",
      "Precis√£o: 0.9213\n",
      "Recall: 0.9411\n",
      "F1-Score: 0.9311\n",
      "\n",
      "Treinando XGBoost Classifier...\n",
      "M√©tricas para XGBoost Classifier:\n",
      "Acur√°cia: 0.9041\n",
      "Precis√£o: 0.9042\n",
      "Recall: 0.9999\n",
      "F1-Score: 0.9497\n",
      "\n",
      "--- Salvando o modelo e o scaler no novo diret√≥rio ---\n",
      "Modelo de churn salvo com sucesso!\n",
      "Scaler salvo com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Supondo que df_orders, df_order_payments e df_orders_reviews j√° est√£o carregados na sua sess√£o.\n",
    "\n",
    "# FUN√á√ÉO DE CONVERS√ÉO: Necess√°ria para lidar com os timestamps\n",
    "def safe_timestamp_to_datetime(series):\n",
    "    series = pd.to_numeric(series, errors='coerce')\n",
    "    if series.dropna().empty:\n",
    "        return pd.NaT\n",
    "    max_val = series.max()\n",
    "    if max_val > 1e18:           # nanosegundos\n",
    "        unit = 'ns'\n",
    "    elif max_val > 1e12:         # milissegundos\n",
    "        unit = 'ms'\n",
    "    else:                        # segundos\n",
    "        unit = 's'\n",
    "    return pd.to_datetime(series, unit=unit, errors='coerce')\n",
    "\n",
    "\n",
    "# --- 1. Prepara√ß√£o dos Dados para An√°lise RFM ---\n",
    "print(\"Preparando dados para an√°lise RFM e predi√ß√£o de Churn...\")\n",
    "\n",
    "# Converte datas para o tipo datetime usando a fun√ß√£o segura\n",
    "df_orders['order_purchase_datetime'] = safe_timestamp_to_datetime(df_orders['order_purchase_timestamp'])\n",
    "\n",
    "# CORRE√á√ÉO: Converte a coluna 'review_score' para num√©rico antes de ser usada no groupby\n",
    "df_orders_reviews['review_score'] = pd.to_numeric(df_orders_reviews['review_score'], errors='coerce')\n",
    "\n",
    "df_order_payments['payment_value'] = pd.to_numeric(df_order_payments['payment_value'], errors='coerce')\n",
    "\n",
    "\n",
    "# Cria um DataFrame unificado para clientes e pedidos\n",
    "df_customers_orders = df_orders.merge(\n",
    "    df_order_payments[['order_id', 'payment_value']],\n",
    "    on='order_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Adiciona a nota de avalia√ß√£o √† tabela de clientes\n",
    "df_customers_reviews = df_orders.merge(\n",
    "    df_orders_reviews[['order_id', 'review_score']],\n",
    "    on='order_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "\n",
    "# --- 2. Cria√ß√£o das Features RFM (Rec√™ncia, Frequ√™ncia, Valor) ---\n",
    "\n",
    "# Define a data de refer√™ncia como a data da √∫ltima compra do dataset + 1 dia\n",
    "reference_date = df_customers_orders['order_purchase_datetime'].max() + pd.DateOffset(days=1)\n",
    "\n",
    "# Calcula as m√©tricas RFM\n",
    "rfm_df = df_customers_orders.groupby('customer_id').agg(\n",
    "    recency_days=('order_purchase_datetime', lambda x: (reference_date - x.max()).days),\n",
    "    frequency_orders=('order_id', 'count'),\n",
    "    monetary_value=('payment_value', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Calcula a nota de avalia√ß√£o m√©dia por cliente\n",
    "avg_review_score = df_customers_reviews.groupby('customer_id')['review_score'].mean().reset_index()\n",
    "rfm_df = rfm_df.merge(avg_review_score, on='customer_id', how='left')\n",
    "\n",
    "\n",
    "# --- 3. Defini√ß√£o da Vari√°vel Alvo 'is_churn' ---\n",
    "# Define churn como clientes que n√£o compraram nos √∫ltimos 90 dias\n",
    "churn_window_days = 90\n",
    "rfm_df['is_churn'] = rfm_df['recency_days'].apply(lambda x: 1 if x > churn_window_days else 0)\n",
    "\n",
    "print(\"Dados RFM e Churn criados:\")\n",
    "print(rfm_df.head())\n",
    "\n",
    "\n",
    "# --- 4. Modelagem para prever 'is_churn' (Classifica√ß√£o) ---\n",
    "print(\"\\n--- Modelagem para prever a evas√£o de clientes (Churn) ---\")\n",
    "\n",
    "# CORRE√á√ÉO: A feature 'recency_days' foi removida, pois ela causa vazamento de dados.\n",
    "features = ['frequency_orders', 'monetary_value', 'review_score']\n",
    "target = 'is_churn'\n",
    "\n",
    "# Trata nulos na review_score (para clientes sem avalia√ß√£o)\n",
    "rfm_df['review_score'] = pd.to_numeric(rfm_df['review_score'], errors='coerce')\n",
    "rfm_df['review_score'].fillna(rfm_df['review_score'].mean(), inplace=True)\n",
    "\n",
    "X = rfm_df[features]\n",
    "y = rfm_df[target]\n",
    "\n",
    "# Padroniza as features num√©ricas\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "models_classification = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=42),\n",
    "    \"Random Forest Classifier\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"XGBoost Classifier\": XGBClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "rf_model_churn = None\n",
    "for name, model in models_classification.items():\n",
    "    print(f\"\\nTreinando {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"M√©tricas para {name}:\")\n",
    "    print(f\"Acur√°cia: {accuracy:.4f}\")\n",
    "    print(f\"Precis√£o: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    \n",
    "    if name == \"Random Forest Classifier\":\n",
    "        rf_model_churn = model\n",
    "\n",
    "# --- üí° NOVO: Salvando o modelo e o scaler no novo diret√≥rio ---\n",
    "print(\"\\n--- Salvando o modelo e o scaler no novo diret√≥rio ---\")\n",
    "# üí° CORRE√á√ÉO: Usa o caminho '..' para subir um n√≠vel antes de entrar na pasta 'models'\n",
    "model_dir = os.path.join('..', 'models', 'churn_rate_model')\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "if rf_model_churn is not None:\n",
    "    joblib.dump(rf_model_churn, os.path.join(model_dir, 'rf_churn_classifier.joblib'))\n",
    "    print(\"Modelo de churn salvo com sucesso!\")\n",
    "    \n",
    "joblib.dump(scaler, os.path.join(model_dir, 'rfm_scaler.joblib'))\n",
    "print(\"Scaler salvo com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a004df",
   "metadata": {},
   "source": [
    "### Treinamento e salvando modelos Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1f336aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a prepara√ß√£o dos dados...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_26324\\643058211.py:38: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_full_orders[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_26324\\643058211.py:38: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_full_orders[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_26324\\643058211.py:38: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_full_orders[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_26324\\643058211.py:38: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_full_orders[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_26324\\643058211.py:38: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_full_orders[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_26324\\643058211.py:38: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_full_orders[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_26324\\643058211.py:38: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_full_orders[col].fillna(median_val, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Modelagem para prever se o cliente est√° satisfeito ---\n",
      "\n",
      "Treinando Logistic Regression...\n",
      "M√©tricas para Logistic Regression:\n",
      "Acur√°cia: 0.7902\n",
      "Precis√£o: 0.7913\n",
      "Recall: 0.9880\n",
      "F1-Score: 0.8788\n",
      "\n",
      "Treinando Random Forest Classifier...\n",
      "M√©tricas para Random Forest Classifier:\n",
      "Acur√°cia: 0.9959\n",
      "Precis√£o: 0.9967\n",
      "Recall: 0.9980\n",
      "F1-Score: 0.9974\n",
      "\n",
      "Treinando XGBoost Classifier...\n",
      "M√©tricas para XGBoost Classifier:\n",
      "Acur√°cia: 0.8010\n",
      "Precis√£o: 0.8037\n",
      "Recall: 0.9811\n",
      "F1-Score: 0.8836\n",
      "\n",
      "--- Salvando o modelo e o encoder ---\n",
      "Modelo e encoder salvos com sucesso!\n",
      "\n",
      "--- Previs√£o de Delivery Delay Hours ---\n",
      "\n",
      "Treinando Linear Regression...\n",
      "M√©tricas para Linear Regression:\n",
      "R¬≤: 0.4912\n",
      "MAE: 128.0181\n",
      "RMSE: 174.9696\n",
      "\n",
      "Treinando Random Forest Regressor...\n",
      "M√©tricas para Random Forest Regressor:\n",
      "R¬≤: 0.9848\n",
      "MAE: 12.7521\n",
      "RMSE: 30.2541\n",
      "\n",
      "Treinando XGBoost Regressor...\n",
      "M√©tricas para XGBoost Regressor:\n",
      "R¬≤: 0.5353\n",
      "MAE: 118.3635\n",
      "RMSE: 167.2154\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# --- 1. Prepara√ß√£o dos Dados ---\n",
    "print(\"Iniciando a prepara√ß√£o dos dados...\")\n",
    "\n",
    "# Lista completa de features num√©ricas e categ√≥ricas\n",
    "all_numeric_features = [\n",
    "    'price',\n",
    "    'freight_value',\n",
    "    'payment_installments',\n",
    "    'total_delivery_time_hours',\n",
    "    'shipping_time_hours',\n",
    "    'product_weight_g',\n",
    "    'product_volume_cm3'\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'customer_state'\n",
    "]\n",
    "\n",
    "# üí° CORRE√á√ÉO CRUCIAL: Converte todas as features num√©ricas para o tipo correto\n",
    "for col in all_numeric_features:\n",
    "    df_full_orders[col] = pd.to_numeric(df_full_orders[col], errors='coerce')\n",
    "\n",
    "# Preenche os valores nulos com a mediana para as colunas num√©ricas\n",
    "for col in all_numeric_features:\n",
    "    median_val = df_full_orders[col].median()\n",
    "    df_full_orders[col].fillna(median_val, inplace=True)\n",
    "\n",
    "# üí° CORRE√á√ÉO: Garante que a coluna review_score seja num√©rica e sem nulos ANTES de us√°-la\n",
    "df_full_orders['review_score'] = pd.to_numeric(df_full_orders['review_score'], errors='coerce')\n",
    "df_full_orders.dropna(subset=['review_score', 'delivery_delay_hours'], inplace=True)\n",
    "\n",
    "# üí° NOVO: Codifica as features categ√≥ricas com One-Hot Encoding\n",
    "one_hot_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "encoded_features = one_hot_encoder.fit_transform(df_full_orders[categorical_features])\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=one_hot_encoder.get_feature_names_out(categorical_features))\n",
    "encoded_df.index = df_full_orders.index\n",
    "\n",
    "# Combina as features num√©ricas e categ√≥ricas\n",
    "X_combined = pd.concat([df_full_orders[all_numeric_features], encoded_df], axis=1)\n",
    "\n",
    "\n",
    "# --- 2. Modelagem para Prever 'is_satisfied' (Classifica√ß√£o) ---\n",
    "print(\"\\n--- Modelagem para prever se o cliente est√° satisfeito ---\")\n",
    "\n",
    "# üí° CORRE√á√ÉO: Garante que a coluna review_score seja num√©rica e sem nulos ANTES de us√°-la\n",
    "df_full_orders['is_satisfied'] = df_full_orders['review_score'].apply(lambda score: 1 if score >= 4 else 0)\n",
    "X = X_combined\n",
    "y_satisfied = df_full_orders['is_satisfied']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_satisfied, test_size=0.20, random_state=42\n",
    ")\n",
    "\n",
    "models_classification = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=42, solver='liblinear'),\n",
    "    \"Random Forest Classifier\": RandomForestClassifier(n_estimators=10, random_state=42),\n",
    "    \"XGBoost Classifier\": XGBClassifier(n_estimators=10, random_state=42)\n",
    "}\n",
    "\n",
    "for name, model in models_classification.items():\n",
    "    print(f\"\\nTreinando {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(f\"M√©tricas para {name}:\")\n",
    "    print(f\"Acur√°cia: {accuracy:.4f}\")\n",
    "    print(f\"Precis√£o: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# --- üí° NOVO: Salvando o modelo e o encoder ---\n",
    "print(\"\\n--- Salvando o modelo e o encoder ---\")\n",
    "# Define o diret√≥rio para salvar\n",
    "model_dir = 'models'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "# Salva o modelo de classifica√ß√£o que voc√™ quer (ex: Random Forest)\n",
    "joblib.dump(models_classification['Random Forest Classifier'], os.path.join(model_dir, 'rf_classifier_satisfied.joblib'))\n",
    "# Salva o encoder para garantir que a API use a mesma codifica√ß√£o\n",
    "joblib.dump(one_hot_encoder, os.path.join(model_dir, 'one_hot_encoder.joblib'))\n",
    "print(\"Modelo e encoder salvos com sucesso!\")\n",
    "\n",
    "\n",
    "# --- 3. Modelagem para Prever 'delivery_delay_hours' (Regress√£o) ---\n",
    "print(\"\\n--- Previs√£o de Delivery Delay Hours ---\")\n",
    "\n",
    "# Garantindo que a coluna de atraso est√° pronta para o modelo\n",
    "df_full_orders['delivery_delay_hours'] = pd.to_numeric(df_full_orders['delivery_delay_hours'], errors='coerce')\n",
    "df_full_orders.dropna(subset=['delivery_delay_hours'], inplace=True)\n",
    "\n",
    "X_delay = X_combined\n",
    "y_delay = df_full_orders['delivery_delay_hours']\n",
    "\n",
    "X_train_delay, X_test_delay, y_train_delay, y_test_delay = train_test_split(\n",
    "    X_delay, y_delay, test_size=0.20, random_state=42\n",
    ")\n",
    "\n",
    "models_regression = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(n_estimators=10, random_state=42),\n",
    "    \"XGBoost Regressor\": XGBRegressor(n_estimators=10, random_state=42)\n",
    "}\n",
    "\n",
    "for name, model in models_regression.items():\n",
    "    print(f\"\\nTreinando {name}...\")\n",
    "    model.fit(X_train_delay, y_train_delay)\n",
    "    y_pred_delay = model.predict(X_test_delay)\n",
    "    r2 = r2_score(y_test_delay, y_pred_delay)\n",
    "    mae = mean_absolute_error(y_test_delay, y_pred_delay)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_delay, y_pred_delay))\n",
    "    print(f\"M√©tricas para {name}:\")\n",
    "    print(f\"R¬≤: {r2:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
