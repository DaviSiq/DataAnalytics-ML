{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1daea395",
   "metadata": {},
   "source": [
    "### Predictive modeling of Orders (Order_payment, review, items and Orders)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5b6afc",
   "metadata": {},
   "source": [
    "#### Juntando todas as tabelas em uma sﾃｳ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e91bf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando tabelas do Snowflake...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_28908\\3132649183.py:29: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_orders = pd.read_sql(\"SELECT * FROM orders_refined\", conn)\n",
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_28908\\3132649183.py:30: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_orders_reviews = pd.read_sql(\"SELECT * FROM order_reviews_refined\", conn)\n",
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_28908\\3132649183.py:31: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_order_payments = pd.read_sql(\"SELECT * FROM order_payments_refined\", conn)\n",
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_28908\\3132649183.py:32: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_order_items = pd.read_sql(\"SELECT * FROM order_items_refined\", conn)\n",
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_28908\\3132649183.py:33: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_products = pd.read_sql(\"SELECT * FROM products_refined\", conn)\n",
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_28908\\3132649183.py:35: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_customers = pd.read_sql(\"SELECT * FROM customers_refined\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unindo as tabelas...\n",
      "Junﾃｧﾃ｣o completa. O DataFrame final tem o formato: (476572, 56)\n",
      "                           order_id                       customer_id  \\\n",
      "0  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
      "1  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
      "2  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
      "3  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
      "4  85ce859fd6dc634de8d2f1e290444043  059f7fc5719c7da6cbafe370971a8d70   \n",
      "\n",
      "  order_status order_purchase_timestamp    order_approved_at  \\\n",
      "0    delivered      1511033286000000000  1511034359000000000   \n",
      "1    delivered      1511033286000000000  1511034359000000000   \n",
      "2    delivered      1511033286000000000  1511034359000000000   \n",
      "3    delivered      1511033286000000000  1511034359000000000   \n",
      "4    delivered      1511222621000000000  1511223262000000000   \n",
      "\n",
      "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
      "0          1511357999000000000           1512174522000000000   \n",
      "1          1511357999000000000           1512174522000000000   \n",
      "2          1511357999000000000           1512174522000000000   \n",
      "3          1511357999000000000           1512174522000000000   \n",
      "4          1511472746000000000           1511807280000000000   \n",
      "\n",
      "  order_estimated_delivery_date approval_time_hours processing_time_hours  \\\n",
      "0           1513296000000000000                 0.3                  89.9   \n",
      "1           1513296000000000000                 0.3                  89.9   \n",
      "2           1513296000000000000                 0.3                  89.9   \n",
      "3           1513296000000000000                 0.3                  89.9   \n",
      "4           1512950400000000000                0.18                  69.3   \n",
      "\n",
      "   ... product_photos_qty product_weight_g product_length_cm  \\\n",
      "0  ...                  3              450                30   \n",
      "1  ...                  3              450                30   \n",
      "2  ...                  3              450                30   \n",
      "3  ...                  3              450                30   \n",
      "4  ...                  1              250                40   \n",
      "\n",
      "  product_height_cm product_width_cm product_volume_cm3 product_density_g_cm3  \\\n",
      "0                10               20               6000                 0.075   \n",
      "1                10               20               6000                 0.075   \n",
      "2                10               20               6000                 0.075   \n",
      "3                10               20               6000                 0.075   \n",
      "4                 4               30               4800                0.0521   \n",
      "\n",
      "  description_category customer_state customer_zip_code_prefix  \n",
      "0      Descriﾃｧﾃ｣o longa             RN                    59296  \n",
      "1      Descriﾃｧﾃ｣o longa             RN                    59296  \n",
      "2      Descriﾃｧﾃ｣o longa             RN                    59296  \n",
      "3      Descriﾃｧﾃ｣o longa             RN                    59296  \n",
      "4      Descriﾃｧﾃ｣o mﾃｩdia             SP                    13186  \n",
      "\n",
      "[5 rows x 56 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import snowflake.connector\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "# Carrega as variﾃ｡veis de ambiente\n",
    "env_path = Path('.') / 'environment.env'\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "SF_USER = os.getenv(\"SF_USER\")\n",
    "SF_PASSWORD = os.getenv(\"SF_PASSWORD\")\n",
    "SF_ACCOUNT = os.getenv(\"SF_ACCOUNT\")\n",
    "SF_WAREHOUSE = os.getenv(\"SF_WAREHOUSE\")\n",
    "SF_DATABASE = os.getenv(\"SF_DATABASE\")\n",
    "SF_SCHEMA = os.getenv(\"SF_SCHEMA\")\n",
    "\n",
    "# Conecta ao Snowflake\n",
    "conn = snowflake.connector.connect(\n",
    "    user=SF_USER,\n",
    "    password=SF_PASSWORD,\n",
    "    account=SF_ACCOUNT,\n",
    "    warehouse=SF_WAREHOUSE,\n",
    "    database=SF_DATABASE,\n",
    "    schema=SF_SCHEMA\n",
    ")\n",
    "\n",
    "# Carrega as tabelas\n",
    "print(\"Carregando tabelas do Snowflake...\")\n",
    "df_orders = pd.read_sql(\"SELECT * FROM orders_refined\", conn)\n",
    "df_orders_reviews = pd.read_sql(\"SELECT * FROM order_reviews_refined\", conn)\n",
    "df_order_payments = pd.read_sql(\"SELECT * FROM order_payments_refined\", conn)\n",
    "df_order_items = pd.read_sql(\"SELECT * FROM order_items_refined\", conn)\n",
    "df_products = pd.read_sql(\"SELECT * FROM products_refined\", conn)\n",
    "# 庁 NOVO: Carregando a tabela de clientes\n",
    "df_customers = pd.read_sql(\"SELECT * FROM customers_refined\", conn)\n",
    "\n",
    "# Fecha a conexﾃ｣o\n",
    "conn.close()\n",
    "\n",
    "# Padroniza os nomes das colunas\n",
    "for df in [df_orders, df_orders_reviews, df_order_payments, df_order_items, df_products, df_customers]:\n",
    "    df.columns = df.columns.str.lower()\n",
    "\n",
    "# Realiza as junﾃｧﾃｵes sequenciais\n",
    "print(\"Unindo as tabelas...\")\n",
    "df_full_orders = df_orders.merge(df_orders_reviews, on='order_id', how='left')\n",
    "df_full_orders = df_full_orders.merge(df_order_payments, on='order_id', how='left')\n",
    "df_full_orders = df_full_orders.merge(df_order_items, on='order_id', how='left')\n",
    "df_full_orders = df_full_orders.merge(df_products, on='product_id', how='left')\n",
    "# 庁 NOVO: Juntando a tabela de clientes\n",
    "df_full_orders = df_full_orders.merge(\n",
    "    df_customers[['customer_id', 'customer_state', 'customer_zip_code_prefix']],\n",
    "    on='customer_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(\"Junﾃｧﾃ｣o completa. O DataFrame final tem o formato:\", df_full_orders.shape)\n",
    "print(df_full_orders.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cd45b1",
   "metadata": {},
   "source": [
    "### Salvando de volta para csv (com todas as tabelas) para usar exemplos reais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c858c06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando tabelas do Snowflake...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_26324\\1455172169.py:29: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_orders = pd.read_sql(\"SELECT * FROM orders_refined\", conn)\n",
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_26324\\1455172169.py:30: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_orders_reviews = pd.read_sql(\"SELECT * FROM order_reviews_refined\", conn)\n",
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_26324\\1455172169.py:31: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_order_payments = pd.read_sql(\"SELECT * FROM order_payments_refined\", conn)\n",
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_26324\\1455172169.py:32: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_order_items = pd.read_sql(\"SELECT * FROM order_items_refined\", conn)\n",
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_26324\\1455172169.py:33: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_products = pd.read_sql(\"SELECT * FROM products_refined\", conn)\n",
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_26324\\1455172169.py:34: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_customers = pd.read_sql(\"SELECT * FROM customers_refined\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unindo as tabelas...\n",
      "Salvando o DataFrame completo em olist_full_dataset.csv...\n",
      "Processo concluﾃｭdo. O arquivo 'olist_full_dataset.csv' foi criado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import snowflake.connector\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "# Carrega as variﾃ｡veis de ambiente\n",
    "env_path = Path('.') / 'environment.env'\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "SF_USER = os.getenv(\"SF_USER\")\n",
    "SF_PASSWORD = os.getenv(\"SF_PASSWORD\")\n",
    "SF_ACCOUNT = os.getenv(\"SF_ACCOUNT\")\n",
    "SF_WAREHOUSE = os.getenv(\"SF_WAREHOUSE\")\n",
    "SF_DATABASE = os.getenv(\"SF_DATABASE\")\n",
    "SF_SCHEMA = os.getenv(\"SF_SCHEMA\")\n",
    "\n",
    "# Conecta ao Snowflake\n",
    "conn = snowflake.connector.connect(\n",
    "    user=SF_USER,\n",
    "    password=SF_PASSWORD,\n",
    "    account=SF_ACCOUNT,\n",
    "    warehouse=SF_WAREHOUSE,\n",
    "    database=SF_DATABASE,\n",
    "    schema=SF_SCHEMA\n",
    ")\n",
    "\n",
    "# Carrega as tabelas\n",
    "print(\"Carregando tabelas do Snowflake...\")\n",
    "df_orders = pd.read_sql(\"SELECT * FROM orders_refined\", conn)\n",
    "df_orders_reviews = pd.read_sql(\"SELECT * FROM order_reviews_refined\", conn)\n",
    "df_order_payments = pd.read_sql(\"SELECT * FROM order_payments_refined\", conn)\n",
    "df_order_items = pd.read_sql(\"SELECT * FROM order_items_refined\", conn)\n",
    "df_products = pd.read_sql(\"SELECT * FROM products_refined\", conn)\n",
    "df_customers = pd.read_sql(\"SELECT * FROM customers_refined\", conn)\n",
    "\n",
    "# Fecha a conexﾃ｣o\n",
    "conn.close()\n",
    "\n",
    "# Padroniza os nomes das colunas\n",
    "for df in [df_orders, df_orders_reviews, df_order_payments, df_order_items, df_products, df_customers]:\n",
    "    df.columns = df.columns.str.lower()\n",
    "\n",
    "# Realiza as junﾃｧﾃｵes sequenciais\n",
    "print(\"Unindo as tabelas...\")\n",
    "df_full_orders = df_orders.merge(df_orders_reviews, on='order_id', how='left')\n",
    "df_full_orders = df_full_orders.merge(df_order_payments, on='order_id', how='left')\n",
    "df_full_orders = df_full_orders.merge(df_order_items, on='order_id', how='left')\n",
    "df_full_orders = df_full_orders.merge(df_products, on='product_id', how='left')\n",
    "df_full_orders = df_full_orders.merge(\n",
    "    df_customers[['customer_id', 'customer_state', 'customer_zip_code_prefix']],\n",
    "    on='customer_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Salva o DataFrame completo em um arquivo CSV\n",
    "print(\"Salvando o DataFrame completo em olist_full_dataset.csv...\")\n",
    "df_full_orders.to_csv('olist_full_dataset.csv', index=False)\n",
    "\n",
    "print(\"Processo concluﾃｭdo. O arquivo 'olist_full_dataset.csv' foi criado com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea2c9da",
   "metadata": {},
   "source": [
    "### Criando dataset monthly_revenue para prediﾃｧﾃ｣o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03a41c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparando dados para a sﾃｩrie temporal de faturamento...\n",
      "Criando a sﾃｩrie temporal de faturamento mensal...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_28908\\1667327117.py:40: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  pd.Grouper(key='order_purchase_datetime', freq='M')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criando features de lag e temporais...\n",
      "\n",
      "DataFrame de Faturamento Mensal com Features de Lag:\n",
      "        data                                 faturamento_mensal  \\\n",
      "3 2016-12-31                                              19.62   \n",
      "4 2017-01-31  19.6219.6211.6216.6218.6219.6220.6219.6219.621...   \n",
      "5 2017-02-28  174.5452.7847.6870.28176.3970.2840.52179.3559....   \n",
      "6 2017-03-31  52.1849.96118.0343.05188.1849.52147.0666.9940....   \n",
      "7 2017-04-30  84.1536.86204.08161.05103.1143.05114.79113.768...   \n",
      "\n",
      "                            faturamento_mes_anterior  \\\n",
      "3                                                  0   \n",
      "4                                              19.62   \n",
      "5  19.6219.6211.6216.6218.6219.6220.6219.6219.621...   \n",
      "6  174.5452.7847.6870.28176.3970.2840.52179.3559....   \n",
      "7  52.1849.96118.0343.05188.1849.52147.0666.9940....   \n",
      "\n",
      "                           faturamento_2_meses_atras  \\\n",
      "3  109.3445.4639.0935.6153.73133.4640.95154.5792....   \n",
      "4                                                  0   \n",
      "5                                              19.62   \n",
      "6  19.6219.6211.6216.6218.6219.6220.6219.6219.621...   \n",
      "7  174.5452.7847.6870.28176.3970.2840.52179.3559....   \n",
      "\n",
      "                           faturamento_3_meses_atras  mes   ano  \n",
      "3                                   136.2375.0640.95   12  2016  \n",
      "4  109.3445.4639.0935.6153.73133.4640.95154.5792....    1  2017  \n",
      "5                                                  0    2  2017  \n",
      "6                                              19.62    3  2017  \n",
      "7  19.6219.6211.6216.6218.6219.6220.6219.6219.621...    4  2017  \n",
      "\n",
      "DataFrame final tem o formato: (23, 7)\n",
      "Salvando o DataFrame de faturamento mensal em 'olist_monthly_revenue.csv'...\n",
      "Arquivo 'olist_full_dataset.csv' criado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Supondo que df_orders e df_order_payments jﾃ｡ estﾃ｣o carregados\n",
    "\n",
    "# 庁 FUNﾃﾃグ DE CONVERSﾃグ CORRIGIDA\n",
    "# Esta funﾃｧﾃ｣o garante que timestamps muito grandes sejam convertidos corretamente\n",
    "def safe_timestamp_to_datetime(series):\n",
    "    series = pd.to_numeric(series, errors='coerce')\n",
    "    if series.dropna().empty:\n",
    "        return pd.NaT\n",
    "    max_val = series.max()\n",
    "    if max_val > 1e18:           # nanosegundos\n",
    "        unit = 'ns'\n",
    "    elif max_val > 1e12:         # milissegundos\n",
    "        unit = 'ms'\n",
    "    else:                        # segundos\n",
    "        unit = 's'\n",
    "    return pd.to_datetime(series, unit=unit, errors='coerce')\n",
    "\n",
    "\n",
    "# --- 1. Junﾃｧﾃ｣o e Preparaﾃｧﾃ｣o dos Dados ---\n",
    "print(\"Preparando dados para a sﾃｩrie temporal de faturamento...\")\n",
    "\n",
    "# Junta pedidos e pagamentos\n",
    "df_revenue = df_orders.merge(\n",
    "    df_order_payments[['order_id', 'payment_value']],\n",
    "    on='order_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# 庁 CORREﾃﾃグ: Usa a funﾃｧﾃ｣o segura para converter o timestamp\n",
    "df_revenue['order_purchase_datetime'] = safe_timestamp_to_datetime(df_revenue['order_purchase_timestamp'])\n",
    "\n",
    "\n",
    "# --- 2. Criaﾃｧﾃ｣o da Sﾃｩrie Temporal de Faturamento Mensal ---\n",
    "print(\"Criando a sﾃｩrie temporal de faturamento mensal...\")\n",
    "\n",
    "# Agrupa por mﾃｪs e soma o valor dos pagamentos\n",
    "monthly_revenue = df_revenue.groupby(\n",
    "    pd.Grouper(key='order_purchase_datetime', freq='M')\n",
    ")['payment_value'].sum().reset_index()\n",
    "\n",
    "# Renomeia as colunas\n",
    "monthly_revenue.rename(columns={'order_purchase_datetime': 'data', 'payment_value': 'faturamento_mensal'}, inplace=True)\n",
    "\n",
    "\n",
    "# --- 3. Criaﾃｧﾃ｣o das Features de Lag e Temporais ---\n",
    "print(\"Criando features de lag e temporais...\")\n",
    "\n",
    "# Features de Lag (faturamento dos meses anteriores)\n",
    "monthly_revenue['faturamento_mes_anterior'] = monthly_revenue['faturamento_mensal'].shift(1)\n",
    "monthly_revenue['faturamento_2_meses_atras'] = monthly_revenue['faturamento_mensal'].shift(2)\n",
    "monthly_revenue['faturamento_3_meses_atras'] = monthly_revenue['faturamento_mensal'].shift(3)\n",
    "\n",
    "# Features Temporais\n",
    "monthly_revenue['mes'] = monthly_revenue['data'].dt.month\n",
    "monthly_revenue['ano'] = monthly_revenue['data'].dt.year\n",
    "\n",
    "# Remove as linhas com valores nulos (os primeiros meses que nﾃ｣o tﾃｪm lag)\n",
    "monthly_revenue.dropna(inplace=True)\n",
    "\n",
    "# Exibe o DataFrame final\n",
    "print(\"\\nDataFrame de Faturamento Mensal com Features de Lag:\")\n",
    "print(monthly_revenue.head())\n",
    "print(f\"\\nDataFrame final tem o formato: {monthly_revenue.shape}\")\n",
    "# --- Adicione este trecho de cﾃｳdigo ao final da sua cﾃｩlula ---\n",
    "\n",
    "# Salva o DataFrame final em um arquivo CSV\n",
    "print(\"Salvando o DataFrame de faturamento mensal em 'olist_monthly_revenue.csv'...\")\n",
    "monthly_revenue.to_csv('olist_monthly_revenue.csv', index=False)\n",
    "\n",
    "print(\"Arquivo 'olist_full_dataset.csv' criado com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ab4eeb",
   "metadata": {},
   "source": [
    "### Treinando o modelo para prever o faturamento de um mﾃｪs X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db284e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recriando e limpando o DataFrame de faturamento mensal...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_28908\\2723260769.py:38: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  pd.Grouper(key='order_purchase_datetime', freq='M')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Previsﾃ｣o de Faturamento do ﾃ嗟timo Mﾃｪs ---\n",
      "Dados de treino: 22 meses\n",
      "Dados de teste: 1 mﾃｪs\n",
      "\n",
      "--- Anﾃ｡lise da Prediﾃｧﾃ｣o ---\n",
      "Faturamento real do ﾃｺltimo mﾃｪs: R$ 589.67\n",
      "Faturamento previsto para o ﾃｺltimo mﾃｪs: R$ 549333.32\n",
      "Diferenﾃｧa (Real - Previsto): R$ -548743.65\n",
      "Erro percentual: 93059.45%\n",
      "\n",
      "--- Salvando o DataFrame de Faturamento Mensal ---\n",
      "Arquivo 'olist_monthly_revenue.csv' criado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Supondo que df_orders e df_order_payments jﾃ｡ estﾃ｣o carregados na sua sessﾃ｣o\n",
    "\n",
    "# 庁 FUNﾃﾃグ DE CONVERSﾃグ: Necessﾃ｡ria para lidar com os timestamps\n",
    "def safe_timestamp_to_datetime(series):\n",
    "    series = pd.to_numeric(series, errors='coerce')\n",
    "    if series.dropna().empty:\n",
    "        return pd.NaT\n",
    "    max_val = series.max()\n",
    "    if max_val > 1e18:           # nanosegundos\n",
    "        unit = 'ns'\n",
    "    elif max_val > 1e12:         # milissegundos\n",
    "        unit = 'ms'\n",
    "    else:                        # segundos\n",
    "        unit = 's'\n",
    "    return pd.to_datetime(series, unit=unit, errors='coerce')\n",
    "\n",
    "\n",
    "# --- 1. Criaﾃｧﾃ｣o e Limpeza da Sﾃｩrie Temporal de Faturamento ---\n",
    "print(\"Recriando e limpando o DataFrame de faturamento mensal...\")\n",
    "\n",
    "df_revenue = df_orders.merge(\n",
    "    df_order_payments[['order_id', 'payment_value']],\n",
    "    on='order_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "df_revenue['payment_value'] = pd.to_numeric(df_revenue['payment_value'], errors='coerce')\n",
    "df_revenue['order_purchase_datetime'] = safe_timestamp_to_datetime(df_revenue['order_purchase_timestamp'])\n",
    "\n",
    "monthly_revenue = df_revenue.groupby(\n",
    "    pd.Grouper(key='order_purchase_datetime', freq='M')\n",
    ")['payment_value'].sum().reset_index()\n",
    "\n",
    "monthly_revenue.rename(columns={'order_purchase_datetime': 'data', 'payment_value': 'faturamento_mensal'}, inplace=True)\n",
    "\n",
    "# Criaﾃｧﾃ｣o das Features de Lag e Temporais\n",
    "monthly_revenue['faturamento_mes_anterior'] = monthly_revenue['faturamento_mensal'].shift(1)\n",
    "monthly_revenue['faturamento_2_meses_atras'] = monthly_revenue['faturamento_mensal'].shift(2)\n",
    "monthly_revenue['faturamento_3_meses_atras'] = monthly_revenue['faturamento_mensal'].shift(3)\n",
    "\n",
    "monthly_revenue['mes'] = monthly_revenue['data'].dt.month\n",
    "monthly_revenue['ano'] = monthly_revenue['data'].dt.year\n",
    "\n",
    "monthly_revenue.dropna(inplace=True)\n",
    "\n",
    "\n",
    "# --- 2. Treinamento e Prediﾃｧﾃ｣o com Random Forest Regressor ---\n",
    "print(\"\\n--- Previsﾃ｣o de Faturamento do ﾃ嗟timo Mﾃｪs ---\")\n",
    "\n",
    "# 庁 CORREﾃﾃグ: Usando o Random Forest Regressor como modelo principal\n",
    "features = [\n",
    "    'faturamento_mes_anterior',\n",
    "    'faturamento_2_meses_atras',\n",
    "    'faturamento_3_meses_atras',\n",
    "    'mes',\n",
    "    'ano'\n",
    "]\n",
    "\n",
    "X = monthly_revenue[features]\n",
    "y = monthly_revenue['faturamento_mensal']\n",
    "\n",
    "X_train = X.iloc[:-1]\n",
    "y_train = y.iloc[:-1]\n",
    "X_test = X.iloc[-1:]\n",
    "y_test = y.iloc[-1:]\n",
    "\n",
    "print(f\"Dados de treino: {len(X_train)} meses\")\n",
    "print(f\"Dados de teste: {len(X_test)} mﾃｪs\")\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# --- 3. Anﾃ｡lise e Comparaﾃｧﾃ｣o ---\n",
    "print(\"\\n--- Anﾃ｡lise da Prediﾃｧﾃ｣o ---\")\n",
    "print(f\"Faturamento real do ﾃｺltimo mﾃｪs: R$ {y_test.values[0]:.2f}\")\n",
    "print(f\"Faturamento previsto para o ﾃｺltimo mﾃｪs: R$ {y_pred[0]:.2f}\")\n",
    "\n",
    "diferenca = y_test.values[0] - y_pred[0]\n",
    "print(f\"Diferenﾃｧa (Real - Previsto): R$ {diferenca:.2f}\")\n",
    "\n",
    "erro_percentual = (abs(diferenca) / y_test.values[0]) * 100\n",
    "print(f\"Erro percentual: {erro_percentual:.2f}%\")\n",
    "\n",
    "\n",
    "# --- 4. Salvando o CSV ---\n",
    "print(\"\\n--- Salvando o DataFrame de Faturamento Mensal ---\")\n",
    "monthly_revenue.to_csv('olist_monthly_revenue.csv', index=False)\n",
    "print(\"Arquivo 'olist_monthly_revenue.csv' criado com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b578d4ca",
   "metadata": {},
   "source": [
    "- Os dados sﾃ｣o insuficientes para gerar um treinamento que possa predizer com um grau elevado de confianﾃｧa o faturamento do mﾃｪs alvo.\n",
    "- Confira o grﾃ｡fico gerado no arquivo EDA onde mostra o aumento e diminuiﾃｧﾃ｣o das vendas ao decorrer dos meses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec27a5c9",
   "metadata": {},
   "source": [
    "### Churn Rate (evasﾃ｣o de um cliente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e99535b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparando dados para anﾃ｡lise RFM e prediﾃｧﾃ｣o de Churn...\n",
      "Dados RFM e Churn criados:\n",
      "                        customer_id  recency_days  frequency_orders  \\\n",
      "0  00012a2ce6f8dcda20d059ce98491703           338                 1   \n",
      "1  000161a058600d5901f007fab4c27140           459                 1   \n",
      "2  0001fd6190edaaf884bcaf3d49edf079           597                 1   \n",
      "3  0002414f95344307404f0ace7a26f1d5           428                 1   \n",
      "4  000379cdec625522490c315e70c7a9fb           199                 1   \n",
      "\n",
      "   monetary_value  review_score  is_churn  \n",
      "0          114.74           1.0         1  \n",
      "1           67.41           4.0         1  \n",
      "2          195.42           5.0         1  \n",
      "3          179.35           5.0         1  \n",
      "4          107.01           4.0         1  \n",
      "\n",
      "--- Modelagem para prever a evasﾃ｣o de clientes (Churn) ---\n",
      "\n",
      "Treinando Logistic Regression...\n",
      "Mﾃｩtricas para Logistic Regression:\n",
      "Acurﾃ｡cia: 0.9042\n",
      "Precisﾃ｣o: 0.9042\n",
      "Recall: 1.0000\n",
      "F1-Score: 0.9497\n",
      "\n",
      "Treinando Random Forest Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_28908\\3029396872.py:92: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  rfm_df['review_score'].fillna(rfm_df['review_score'].mean(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mﾃｩtricas para Random Forest Classifier:\n",
      "Acurﾃ｡cia: 0.8740\n",
      "Precisﾃ｣o: 0.9213\n",
      "Recall: 0.9411\n",
      "F1-Score: 0.9311\n",
      "\n",
      "Treinando XGBoost Classifier...\n",
      "Mﾃｩtricas para XGBoost Classifier:\n",
      "Acurﾃ｡cia: 0.9041\n",
      "Precisﾃ｣o: 0.9042\n",
      "Recall: 0.9999\n",
      "F1-Score: 0.9497\n",
      "\n",
      "--- Salvando o modelo e o scaler no novo diretﾃｳrio ---\n",
      "Modelo de churn salvo com sucesso!\n",
      "Scaler salvo com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Supondo que df_orders, df_order_payments e df_orders_reviews jﾃ｡ estﾃ｣o carregados na sua sessﾃ｣o.\n",
    "\n",
    "# FUNﾃﾃグ DE CONVERSﾃグ: Necessﾃ｡ria para lidar com os timestamps\n",
    "def safe_timestamp_to_datetime(series):\n",
    "    series = pd.to_numeric(series, errors='coerce')\n",
    "    if series.dropna().empty:\n",
    "        return pd.NaT\n",
    "    max_val = series.max()\n",
    "    if max_val > 1e18:           # nanosegundos\n",
    "        unit = 'ns'\n",
    "    elif max_val > 1e12:         # milissegundos\n",
    "        unit = 'ms'\n",
    "    else:                        # segundos\n",
    "        unit = 's'\n",
    "    return pd.to_datetime(series, unit=unit, errors='coerce')\n",
    "\n",
    "\n",
    "# --- 1. Preparaﾃｧﾃ｣o dos Dados para Anﾃ｡lise RFM ---\n",
    "print(\"Preparando dados para anﾃ｡lise RFM e prediﾃｧﾃ｣o de Churn...\")\n",
    "\n",
    "# Converte datas para o tipo datetime usando a funﾃｧﾃ｣o segura\n",
    "df_orders['order_purchase_datetime'] = safe_timestamp_to_datetime(df_orders['order_purchase_timestamp'])\n",
    "\n",
    "# CORREﾃﾃグ: Converte a coluna 'review_score' para numﾃｩrico antes de ser usada no groupby\n",
    "df_orders_reviews['review_score'] = pd.to_numeric(df_orders_reviews['review_score'], errors='coerce')\n",
    "\n",
    "df_order_payments['payment_value'] = pd.to_numeric(df_order_payments['payment_value'], errors='coerce')\n",
    "\n",
    "\n",
    "# Cria um DataFrame unificado para clientes e pedidos\n",
    "df_customers_orders = df_orders.merge(\n",
    "    df_order_payments[['order_id', 'payment_value']],\n",
    "    on='order_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Adiciona a nota de avaliaﾃｧﾃ｣o ﾃ tabela de clientes\n",
    "df_customers_reviews = df_orders.merge(\n",
    "    df_orders_reviews[['order_id', 'review_score']],\n",
    "    on='order_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "\n",
    "# --- 2. Criaﾃｧﾃ｣o das Features RFM (Recﾃｪncia, Frequﾃｪncia, Valor) ---\n",
    "\n",
    "# Define a data de referﾃｪncia como a data da ﾃｺltima compra do dataset + 1 dia\n",
    "reference_date = df_customers_orders['order_purchase_datetime'].max() + pd.DateOffset(days=1)\n",
    "\n",
    "# Calcula as mﾃｩtricas RFM\n",
    "rfm_df = df_customers_orders.groupby('customer_id').agg(\n",
    "    recency_days=('order_purchase_datetime', lambda x: (reference_date - x.max()).days),\n",
    "    frequency_orders=('order_id', 'count'),\n",
    "    monetary_value=('payment_value', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Calcula a nota de avaliaﾃｧﾃ｣o mﾃｩdia por cliente\n",
    "avg_review_score = df_customers_reviews.groupby('customer_id')['review_score'].mean().reset_index()\n",
    "rfm_df = rfm_df.merge(avg_review_score, on='customer_id', how='left')\n",
    "\n",
    "\n",
    "# --- 3. Definiﾃｧﾃ｣o da Variﾃ｡vel Alvo 'is_churn' ---\n",
    "# Define churn como clientes que nﾃ｣o compraram nos ﾃｺltimos 90 dias\n",
    "churn_window_days = 90\n",
    "rfm_df['is_churn'] = rfm_df['recency_days'].apply(lambda x: 1 if x > churn_window_days else 0)\n",
    "\n",
    "print(\"Dados RFM e Churn criados:\")\n",
    "print(rfm_df.head())\n",
    "\n",
    "\n",
    "# --- 4. Modelagem para prever 'is_churn' (Classificaﾃｧﾃ｣o) ---\n",
    "print(\"\\n--- Modelagem para prever a evasﾃ｣o de clientes (Churn) ---\")\n",
    "\n",
    "# CORREﾃﾃグ: A feature 'recency_days' foi removida, pois ela causa vazamento de dados.\n",
    "features = ['frequency_orders', 'monetary_value', 'review_score']\n",
    "target = 'is_churn'\n",
    "\n",
    "# Trata nulos na review_score (para clientes sem avaliaﾃｧﾃ｣o)\n",
    "rfm_df['review_score'] = pd.to_numeric(rfm_df['review_score'], errors='coerce')\n",
    "rfm_df['review_score'].fillna(rfm_df['review_score'].mean(), inplace=True)\n",
    "\n",
    "X = rfm_df[features]\n",
    "y = rfm_df[target]\n",
    "\n",
    "# Padroniza as features numﾃｩricas\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "models_classification = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=42),\n",
    "    \"Random Forest Classifier\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"XGBoost Classifier\": XGBClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "rf_model_churn = None\n",
    "for name, model in models_classification.items():\n",
    "    print(f\"\\nTreinando {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Mﾃｩtricas para {name}:\")\n",
    "    print(f\"Acurﾃ｡cia: {accuracy:.4f}\")\n",
    "    print(f\"Precisﾃ｣o: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    \n",
    "    if name == \"Random Forest Classifier\":\n",
    "        rf_model_churn = model\n",
    "\n",
    "# --- 庁 NOVO: Salvando o modelo e o scaler no novo diretﾃｳrio ---\n",
    "print(\"\\n--- Salvando o modelo e o scaler no novo diretﾃｳrio ---\")\n",
    "# 庁 CORREﾃﾃグ: Usa o caminho '..' para subir um nﾃｭvel antes de entrar na pasta 'models'\n",
    "model_dir = os.path.join('..', 'models', 'churn_rate_model')\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "if rf_model_churn is not None:\n",
    "    joblib.dump(rf_model_churn, os.path.join(model_dir, 'rf_churn_classifier.joblib'))\n",
    "    print(\"Modelo de churn salvo com sucesso!\")\n",
    "    \n",
    "joblib.dump(scaler, os.path.join(model_dir, 'rfm_scaler.joblib'))\n",
    "print(\"Scaler salvo com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a004df",
   "metadata": {},
   "source": [
    "### Treinamento e salvando modelos Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1f336aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a preparaﾃｧﾃ｣o dos dados...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_26324\\643058211.py:38: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_full_orders[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_26324\\643058211.py:38: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_full_orders[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_26324\\643058211.py:38: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_full_orders[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_26324\\643058211.py:38: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_full_orders[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_26324\\643058211.py:38: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_full_orders[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_26324\\643058211.py:38: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_full_orders[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\pacie\\AppData\\Local\\Temp\\ipykernel_26324\\643058211.py:38: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_full_orders[col].fillna(median_val, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Modelagem para prever se o cliente estﾃ｡ satisfeito ---\n",
      "\n",
      "Treinando Logistic Regression...\n",
      "Mﾃｩtricas para Logistic Regression:\n",
      "Acurﾃ｡cia: 0.7902\n",
      "Precisﾃ｣o: 0.7913\n",
      "Recall: 0.9880\n",
      "F1-Score: 0.8788\n",
      "\n",
      "Treinando Random Forest Classifier...\n",
      "Mﾃｩtricas para Random Forest Classifier:\n",
      "Acurﾃ｡cia: 0.9959\n",
      "Precisﾃ｣o: 0.9967\n",
      "Recall: 0.9980\n",
      "F1-Score: 0.9974\n",
      "\n",
      "Treinando XGBoost Classifier...\n",
      "Mﾃｩtricas para XGBoost Classifier:\n",
      "Acurﾃ｡cia: 0.8010\n",
      "Precisﾃ｣o: 0.8037\n",
      "Recall: 0.9811\n",
      "F1-Score: 0.8836\n",
      "\n",
      "--- Salvando o modelo e o encoder ---\n",
      "Modelo e encoder salvos com sucesso!\n",
      "\n",
      "--- Previsﾃ｣o de Delivery Delay Hours ---\n",
      "\n",
      "Treinando Linear Regression...\n",
      "Mﾃｩtricas para Linear Regression:\n",
      "Rﾂｲ: 0.4912\n",
      "MAE: 128.0181\n",
      "RMSE: 174.9696\n",
      "\n",
      "Treinando Random Forest Regressor...\n",
      "Mﾃｩtricas para Random Forest Regressor:\n",
      "Rﾂｲ: 0.9848\n",
      "MAE: 12.7521\n",
      "RMSE: 30.2541\n",
      "\n",
      "Treinando XGBoost Regressor...\n",
      "Mﾃｩtricas para XGBoost Regressor:\n",
      "Rﾂｲ: 0.5353\n",
      "MAE: 118.3635\n",
      "RMSE: 167.2154\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# --- 1. Preparaﾃｧﾃ｣o dos Dados ---\n",
    "print(\"Iniciando a preparaﾃｧﾃ｣o dos dados...\")\n",
    "\n",
    "# Lista completa de features numﾃｩricas e categﾃｳricas\n",
    "all_numeric_features = [\n",
    "    'price',\n",
    "    'freight_value',\n",
    "    'payment_installments',\n",
    "    'total_delivery_time_hours',\n",
    "    'shipping_time_hours',\n",
    "    'product_weight_g',\n",
    "    'product_volume_cm3'\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'customer_state'\n",
    "]\n",
    "\n",
    "# 庁 CORREﾃﾃグ CRUCIAL: Converte todas as features numﾃｩricas para o tipo correto\n",
    "for col in all_numeric_features:\n",
    "    df_full_orders[col] = pd.to_numeric(df_full_orders[col], errors='coerce')\n",
    "\n",
    "# Preenche os valores nulos com a mediana para as colunas numﾃｩricas\n",
    "for col in all_numeric_features:\n",
    "    median_val = df_full_orders[col].median()\n",
    "    df_full_orders[col].fillna(median_val, inplace=True)\n",
    "\n",
    "# 庁 CORREﾃﾃグ: Garante que a coluna review_score seja numﾃｩrica e sem nulos ANTES de usﾃ｡-la\n",
    "df_full_orders['review_score'] = pd.to_numeric(df_full_orders['review_score'], errors='coerce')\n",
    "df_full_orders.dropna(subset=['review_score', 'delivery_delay_hours'], inplace=True)\n",
    "\n",
    "# 庁 NOVO: Codifica as features categﾃｳricas com One-Hot Encoding\n",
    "one_hot_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "encoded_features = one_hot_encoder.fit_transform(df_full_orders[categorical_features])\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=one_hot_encoder.get_feature_names_out(categorical_features))\n",
    "encoded_df.index = df_full_orders.index\n",
    "\n",
    "# Combina as features numﾃｩricas e categﾃｳricas\n",
    "X_combined = pd.concat([df_full_orders[all_numeric_features], encoded_df], axis=1)\n",
    "\n",
    "\n",
    "# --- 2. Modelagem para Prever 'is_satisfied' (Classificaﾃｧﾃ｣o) ---\n",
    "print(\"\\n--- Modelagem para prever se o cliente estﾃ｡ satisfeito ---\")\n",
    "\n",
    "# 庁 CORREﾃﾃグ: Garante que a coluna review_score seja numﾃｩrica e sem nulos ANTES de usﾃ｡-la\n",
    "df_full_orders['is_satisfied'] = df_full_orders['review_score'].apply(lambda score: 1 if score >= 4 else 0)\n",
    "X = X_combined\n",
    "y_satisfied = df_full_orders['is_satisfied']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_satisfied, test_size=0.20, random_state=42\n",
    ")\n",
    "\n",
    "models_classification = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=42, solver='liblinear'),\n",
    "    \"Random Forest Classifier\": RandomForestClassifier(n_estimators=10, random_state=42),\n",
    "    \"XGBoost Classifier\": XGBClassifier(n_estimators=10, random_state=42)\n",
    "}\n",
    "\n",
    "for name, model in models_classification.items():\n",
    "    print(f\"\\nTreinando {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(f\"Mﾃｩtricas para {name}:\")\n",
    "    print(f\"Acurﾃ｡cia: {accuracy:.4f}\")\n",
    "    print(f\"Precisﾃ｣o: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# --- 庁 NOVO: Salvando o modelo e o encoder ---\n",
    "print(\"\\n--- Salvando o modelo e o encoder ---\")\n",
    "# Define o diretﾃｳrio para salvar\n",
    "model_dir = 'models'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "# Salva o modelo de classificaﾃｧﾃ｣o que vocﾃｪ quer (ex: Random Forest)\n",
    "joblib.dump(models_classification['Random Forest Classifier'], os.path.join(model_dir, 'rf_classifier_satisfied.joblib'))\n",
    "# Salva o encoder para garantir que a API use a mesma codificaﾃｧﾃ｣o\n",
    "joblib.dump(one_hot_encoder, os.path.join(model_dir, 'one_hot_encoder.joblib'))\n",
    "print(\"Modelo e encoder salvos com sucesso!\")\n",
    "\n",
    "\n",
    "# --- 3. Modelagem para Prever 'delivery_delay_hours' (Regressﾃ｣o) ---\n",
    "print(\"\\n--- Previsﾃ｣o de Delivery Delay Hours ---\")\n",
    "\n",
    "# Garantindo que a coluna de atraso estﾃ｡ pronta para o modelo\n",
    "df_full_orders['delivery_delay_hours'] = pd.to_numeric(df_full_orders['delivery_delay_hours'], errors='coerce')\n",
    "df_full_orders.dropna(subset=['delivery_delay_hours'], inplace=True)\n",
    "\n",
    "X_delay = X_combined\n",
    "y_delay = df_full_orders['delivery_delay_hours']\n",
    "\n",
    "X_train_delay, X_test_delay, y_train_delay, y_test_delay = train_test_split(\n",
    "    X_delay, y_delay, test_size=0.20, random_state=42\n",
    ")\n",
    "\n",
    "models_regression = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(n_estimators=10, random_state=42),\n",
    "    \"XGBoost Regressor\": XGBRegressor(n_estimators=10, random_state=42)\n",
    "}\n",
    "\n",
    "for name, model in models_regression.items():\n",
    "    print(f\"\\nTreinando {name}...\")\n",
    "    model.fit(X_train_delay, y_train_delay)\n",
    "    y_pred_delay = model.predict(X_test_delay)\n",
    "    r2 = r2_score(y_test_delay, y_pred_delay)\n",
    "    mae = mean_absolute_error(y_test_delay, y_pred_delay)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_delay, y_pred_delay))\n",
    "    print(f\"Mﾃｩtricas para {name}:\")\n",
    "    print(f\"Rﾂｲ: {r2:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
